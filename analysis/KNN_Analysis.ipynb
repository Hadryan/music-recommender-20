{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1bf12d2",
   "metadata": {},
   "source": [
    "# KNN approach parameters analysis\n",
    "\n",
    "To get the best out of the KNN model, different features are tested to get the best feature subset that should be used. Also, different K values and different distance metrics are evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c4081383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38d479d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in songs data\n",
    "\n",
    "song_data_df = pd.read_csv('../output.csv', header=0)\n",
    "song_data_df = song_data_df.drop_duplicates(subset=['song_id', 'hotttness', 'familiarity', 'loudness', 'tempo', 'key', 'key_confidence', 'mode', 'mode_confidence'])\n",
    "song_data_df = song_data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "af02819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_feature_array(user_songs, features, scaler):\n",
    "    user_songs_data = song_data_df[song_data_df['song_id'].isin(user_songs)]\n",
    "    rel_data = user_songs_data[features]\n",
    "    s_feat_arr = scaler.transform(rel_data)\n",
    "    return s_feat_arr\n",
    "\n",
    "def content_evaluate(expected, actual):\n",
    "    '''\n",
    "        Function that calculates precision and recall based on expected and actual recommendations.\n",
    "        Precision = TP / (TP + FP)\n",
    "        Recall = TP / (TP + FN)\n",
    "    '''\n",
    "    # intersect is true positives\n",
    "    intersect_list = [value for value in expected if value in set(actual)]\n",
    "\n",
    "    # len(actual) is TP + FP\n",
    "    # len(expected) is TP + FN\n",
    "    score = len(intersect_list)\n",
    "    return score/len(actual), score / len(expected)\n",
    "\n",
    "def run_model(model, feature_array, test_set, n):\n",
    "    similar_song_ids = model.kneighbors(feature_array, return_distance=False).flatten()\n",
    "    \n",
    "    start_ind = len(feature_array)\n",
    "    end_ind = int(start_ind+n)\n",
    "    \n",
    "    topNsongs = similar_song_ids[start_ind:end_ind]\n",
    "    nearest_n = song_data_df.iloc[topNsongs,:][['song_id']]\n",
    "    nearest_n_list = nearest_n['song_id'].tolist()\n",
    "    \n",
    "    precision, recall = content_evaluate(test_set, nearest_n_list)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2c4477",
   "metadata": {},
   "source": [
    "## Feature subset analysis\n",
    "\n",
    "Analysis of what features of songs should be selected as relevant to describe each song.\n",
    "Following groups of features are tested:\n",
    "\n",
    "```\n",
    "relevant_features1 = ['hotttness']\n",
    "relevant_features2 = ['hotttness','familiarity','loudness']\n",
    "relevant_features3 = ['hotttness','familiarity','loudness', 'duration','tempo','key','mode']\n",
    "relevant_features4 = ['hotttness','familiarity','key','mode']\n",
    "relevant_features5 = ['hotttness','familiarity']\n",
    "relevant_features6 = ['familiarity']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "82b963bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_features_subsets = [['hotttness'], ['hotttness','familiarity','loudness'], ['hotttness','familiarity','loudness', 'duration','tempo','key','mode'], ['hotttness','familiarity','key','mode'],  ['hotttness','familiarity'], ['familiarity']]\n",
    "\n",
    "def create_scalers_and_models_for_different_features(features_list):\n",
    "    models, scalers = [], []\n",
    "    for feature_subset in features_list:\n",
    "        train_data = song_data_df[feature_subset]\n",
    "        \n",
    "        scaler = preprocessing.RobustScaler()\n",
    "        train_data_normalized = scaler.fit_transform(train_data)\n",
    "        \n",
    "        KNN = NearestNeighbors(n_neighbors=1000)\n",
    "        KNN.fit(train_data)\n",
    "        \n",
    "        models.append(KNN)\n",
    "        scalers.append(scaler)\n",
    "        \n",
    "    return scalers, models\n",
    "\n",
    "scalers, models = create_scalers_and_models_for_different_features(relevant_features_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d1dd16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in the user data\n",
    "\n",
    "user_data_df = pd.read_csv('../output_plays.csv')\n",
    "user_data_df.columns = ['userID', 'songID', 'playCount']\n",
    "\n",
    "user_data_df = user_data_df[user_data_df['songID'].isin(song_data_df['song_id'].unique().tolist())]\n",
    "\n",
    "user_id_list = user_data_df['userID'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7e3ae29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1253243, 3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bed29fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "samples = np.random.choice(user_id_list, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "873c219d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ['hotttness'] features, average precision: 0.0014333333333333342, average recall: 0.02615\n",
      "For ['hotttness', 'familiarity', 'loudness'] features, average precision: 0.0004999999999999999, average recall: 0.009416666666666667\n",
      "For ['hotttness', 'familiarity', 'loudness', 'duration', 'tempo', 'key', 'mode'] features, average precision: 6.666666666666667e-05, average recall: 0.001\n",
      "For ['hotttness', 'familiarity', 'key', 'mode'] features, average precision: 0.0005666666666666666, average recall: 0.01103333333333333\n",
      "For ['hotttness', 'familiarity'] features, average precision: 0.0014333333333333342, average recall: 0.025709523809523807\n",
      "For ['familiarity'] features, average precision: 0.001333333333333334, average recall: 0.022\n"
     ]
    }
   ],
   "source": [
    "def calculate_precision_and_recall_for_different_features(user_id):\n",
    "    user_listens_data = user_data_df.loc[user_data_df['userID'] == user_id]\n",
    "    \n",
    "    # all unique songs this specific user listens\n",
    "    song_id_list = user_listens_data['songID'].unique().tolist()\n",
    "    \n",
    "    if len(song_id_list) < 4:\n",
    "        return [], []\n",
    "    \n",
    "    # split songs user listens in 75:25\n",
    "    songs_i_train, songs_i_test = train_test_split(song_id_list, test_size=0.25, random_state=42)\n",
    "    \n",
    "    precisions, recalls = [], []\n",
    "    \n",
    "    for features, scaler, model in zip(relevant_features_subsets, scalers, models):\n",
    "\n",
    "        # get normalized song feature array\n",
    "        song_feature_arr = get_song_feature_array(songs_i_train, features, scaler)\n",
    "        p, r = run_model(model, song_feature_arr, songs_i_test, 30)\n",
    "        precisions.append(p)\n",
    "        recalls.append(r)\n",
    "        \n",
    "    return precisions, recalls\n",
    "\n",
    "counter = 1\n",
    "\n",
    "precisions, recalls = [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]\n",
    "for user_id in samples:\n",
    "    user_precisions, user_recalls = calculate_precision_and_recall_for_different_features(user_id)\n",
    "    if not user_precisions or not user_recalls:\n",
    "        continue\n",
    "    \n",
    "    precisions = [precision + user_precisions[idx] for idx, precision in enumerate(precisions)]\n",
    "    recalls = [recall + user_recalls[idx] for idx, recall in enumerate(recalls)]\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    if counter >= 1000:\n",
    "        break\n",
    "\n",
    "for precision, recall, features in zip(precisions, recalls, relevant_features_subsets):\n",
    "    print(f\"For {features} features, average precision: {precision / 1000}, average recall: {recall / 1000}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0cc7b8",
   "metadata": {},
   "source": [
    "## Number K analysis\n",
    "\n",
    "Analysis of best K number for KNN algorithm is given below, where following values are taken in consideration: `[10, 25, 50, 100, 200, 400]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5065164e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K = 10, average precision: 0.0019000000000000006, average recall: 0.011833333333333333\n",
      "For K = 25, average precision: 0.0014800000000000006, average recall: 0.022376190476190473\n",
      "For K = 50, average precision: 0.0011800000000000007, average recall: 0.0347095238095238\n",
      "For K = 100, average precision: 0.001250000000000001, average recall: 0.0706857142857143\n",
      "For K = 200, average precision: 0.001114999999999999, average recall: 0.12993571428571427\n",
      "For K = 400, average precision: 0.0007974999999999959, average recall: 0.1871357142857143\n"
     ]
    }
   ],
   "source": [
    "possible_K_values = [10, 25, 50, 100, 200, 400]\n",
    "\n",
    "features = relevant_features_subsets[4]\n",
    "scaler = scalers[4]\n",
    "model = models[4]\n",
    "\n",
    "def calculate_precision_and_recall_for_different_K(user_id):\n",
    "    user_listens_data = user_data_df.loc[user_data_df['userID'] == user_id]\n",
    "    \n",
    "    # all unique songs this specific user listens\n",
    "    song_id_list = user_listens_data['songID'].unique().tolist()\n",
    "    \n",
    "    if len(song_id_list) < 4:\n",
    "        return [], []\n",
    "    \n",
    "    # split songs user listens in 75:25\n",
    "    songs_i_train, songs_i_test = train_test_split(song_id_list, test_size=0.25, random_state=42)\n",
    "    \n",
    "    precisions, recalls = [], []\n",
    "    \n",
    "    song_feature_arr = get_song_feature_array(songs_i_train, features, scaler)\n",
    "    \n",
    "    for K in possible_K_values:\n",
    "        \n",
    "        p, r = run_model(model, song_feature_arr, songs_i_test, K)\n",
    "        precisions.append(p)\n",
    "        recalls.append(r)\n",
    "        \n",
    "    return precisions, recalls\n",
    "\n",
    "\n",
    "counter = 1\n",
    "\n",
    "precisions, recalls = [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]\n",
    "for user_id in samples:\n",
    "    user_precisions, user_recalls = calculate_precision_and_recall_for_different_K(user_id)\n",
    "    if not user_precisions or not user_recalls:\n",
    "        continue\n",
    "    \n",
    "    precisions = [precision + user_precisions[idx] for idx, precision in enumerate(precisions)]\n",
    "    recalls = [recall + user_recalls[idx] for idx, recall in enumerate(recalls)]\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    if counter >= 1000:\n",
    "        break\n",
    "\n",
    "for precision, recall, K in zip(precisions, recalls, possible_K_values):\n",
    "    print(f\"For K = {K}, average precision: {precision / 1000}, average recall: {recall / 1000}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbc4c76",
   "metadata": {},
   "source": [
    "## Distance metric analysis\n",
    "\n",
    "Analysis to find best distance metric to use for KNN model. Possible values that are taken into consideration are: `['chebyshev', 'minkowski', 'manhattan', 'euclidean']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2db2d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\faks\\master prvi semestar\\napredne\\music-recommender\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=1000 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "d:\\faks\\master prvi semestar\\napredne\\music-recommender\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=1000 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "d:\\faks\\master prvi semestar\\napredne\\music-recommender\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=1000 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "d:\\faks\\master prvi semestar\\napredne\\music-recommender\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=1000 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For distance chebyshev, average precision: 0.0008100000000000006, average recall: 0.04491666666666667\n",
      "For distance minkowski, average precision: 0.0008000000000000005, average recall: 0.04391666666666667\n",
      "For distance manhattan, average precision: 0.0008200000000000006, average recall: 0.04675000000000001\n",
      "For distance euclidean, average precision: 0.0008100000000000006, average recall: 0.044916666666666674\n"
     ]
    }
   ],
   "source": [
    "distances = ['chebyshev', 'minkowski', 'manhattan', 'euclidean']\n",
    "features = relevant_features_subsets[4]\n",
    "\n",
    "train_data = song_data_df[features]\n",
    "\n",
    "scaler = preprocessing.RobustScaler()\n",
    "train_data_normalized = scaler.fit_transform(train_data)\n",
    "\n",
    "KNN1 = NearestNeighbors(n_neighbors=1000,metric='chebyshev')\n",
    "KNN1.fit(train_data_normalized)\n",
    "\n",
    "KNN2 = NearestNeighbors(n_neighbors=1000, metric='minkowski', p=4)\n",
    "KNN2.fit(train_data_normalized)\n",
    "\n",
    "KNN3 = NearestNeighbors(n_neighbors=1000, metric='manhattan')\n",
    "KNN3.fit(train_data_normalized)\n",
    "\n",
    "KNN4 = NearestNeighbors(n_neighbors=1000)\n",
    "KNN4.fit(train_data_normalized) # euclidean\n",
    "\n",
    "models = [KNN1, KNN2, KNN3, KNN4]\n",
    "\n",
    "\n",
    "def calculate_precision_and_recall_for_different_models(user_id):\n",
    "    user_listens_data = user_data_df.loc[user_data_df['userID'] == user_id]\n",
    "    \n",
    "    # all unique songs this specific user listens\n",
    "    song_id_list = user_listens_data['songID'].unique().tolist()\n",
    "    \n",
    "    if len(song_id_list) < 4:\n",
    "        return [], []\n",
    "    \n",
    "    # split songs user listens in 75:25\n",
    "    songs_i_train, songs_i_test = train_test_split(song_id_list, test_size=0.25, random_state=42)\n",
    "    \n",
    "    precisions, recalls = [], []\n",
    "    \n",
    "    song_feature_arr = get_song_feature_array(songs_i_train, features, scaler)\n",
    "    \n",
    "    for model in models:\n",
    "        p, r = run_model(model, song_feature_arr, songs_i_test, 100)\n",
    "        precisions.append(p)\n",
    "        recalls.append(r)\n",
    "        \n",
    "    return precisions, recalls\n",
    "\n",
    "\n",
    "counter = 1\n",
    "\n",
    "precisions, recalls = [0, 0, 0, 0], [0, 0, 0, 0]\n",
    "for user_id in samples:\n",
    "    user_precisions, user_recalls = calculate_precision_and_recall_for_different_models(user_id)\n",
    "    if not user_precisions or not user_recalls:\n",
    "        continue\n",
    "    \n",
    "    precisions = [precision + user_precisions[idx] for idx, precision in enumerate(precisions)]\n",
    "    recalls = [recall + user_recalls[idx] for idx, recall in enumerate(recalls)]\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    if counter >= 1000:\n",
    "        break\n",
    "\n",
    "for precision, recall, distance in zip(precisions, recalls, distances):\n",
    "    print(f\"For distance {distance}, average precision: {precision / 1000}, average recall: {recall / 1000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c534381e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
